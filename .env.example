CHROME_DRIVER_PATH=C:\\chromeDriver\\chromedriver.exe
CHROME_APP_PATH=C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe

# Scraping Chrome Data Directory (Temporary account for scraping, so banning of main account is prevented)
SCRAPING_CHROME_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Viewer\\data\\chromeData\\irangarick
SCRAPING_PORT=9003

# Applying Chrome Data Directory (Main account for applying)
APPLYING_CHROME_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Viewer\\data\\chromeData\\notirangarick
APPLYING_PORT=9005

# Database Configuration
# Options: mysql, sqlite
DB_TYPE=sqlite

# MySQL Database Configuration (used when DB_TYPE=mysql)
MYSQL_URL=mysql://username:password@host:port/database_name

# SQLite Database Configuration (used when DB_TYPE=sqlite)
SQLITE_DB_PATH=C:\\Users\\antonio\\Desktop\\Saral-Job-Viewer\\data\\localDb.sqlite

# Legacy Database URL (for backward compatibility)
DATABASE_URL=mysql://username:password@host:port/database_name

# LinkedIn Questions JSON file path (Merging with a different Application that automatically applies to jobs for Dice and Easy Apply in LinkedIn)
QUESTIONS_JSON=C:\\Users\\antonio\\Desktop\\Saral-Job-Viewer\\data\\linkedinQuestions.json
DATA_DIR=C:\\Users\\antonio\\Desktop\\Saral-Job-Viewer\\data

BASE_PORT=9000


# Current Directory Structure
# Saral-Job-Viewer/
# ├── app.py                    # FastAPI backend server
# ├── linkedInScraping.py       # LinkedIn scraping script
# ├── diceScraping.py          # Dice scraping script
# ├── requirements.txt         # Python dependencies
# ├── .env                     # Environment variables
# ├── .gitignore              # Git ignore file
# ├── utils/
# ├── services/
# ├── data/                    # Data directory for JSON files
#     └── linkedinQuestions.json
#     └── rawData.json
#     └── chromeData/          # Chrome user profiles
#         └── irangarick/      # Profile for scraping
#         └── notirangarick/   # Profile for applying